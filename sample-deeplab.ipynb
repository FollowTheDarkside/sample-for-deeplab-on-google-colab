{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sample-deeplab_forShare.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNpaNLoEyTRMxTF9nr403Qb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"e2CwBjst5PCO"},"source":["# DeepLab\n","Sample for video process\n","<br><br>\n","Reference:\n","<br>\n","https://github.com/tensorflow/models/tree/master/research/deeplab \n","<br>\n","https://colab.research.google.com/github/tensorflow/models/blob/master/research/deeplab/deeplab_demo.ipynb"]},{"cell_type":"code","metadata":{"id":"G-VFOlor49SX"},"source":["# You need to set the runtime type to GPU.\n","\n","# Check GPU Info\n","print(\"=====GPU=====\")\n","!nvidia-smi\n","\n","print(\"=====GPU MEMORY=====\")\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n","    process = psutil.Process(os.getpid())\n","    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()\n","\n","# You can set options in Colab Pro to access high memory VMs as soon as they are available.\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('\\nYour runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9vJqXv655NBP"},"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTr4zni15OK9"},"source":["# Import libraries for DeepLab\n","\n","import os\n","from io import BytesIO\n","import tarfile\n","import tempfile\n","from six.moves import urllib\n","\n","from matplotlib import gridspec\n","from matplotlib import pyplot as plt\n","import numpy as np\n","from PIL import Image\n","\n","import cv2\n","import time\n","\n","%tensorflow_version 1.x\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-yEdsALN7VnO","executionInfo":{"status":"ok","timestamp":1625732955810,"user_tz":-540,"elapsed":310,"user":{"displayName":"Followthedarkside","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkplSIiKYbzSn3GMZUrb-Rpnb-_21qneoWk3QOPQ=s64","userId":"04286352552701960109"}}},"source":["# Import helper methods\n","\n","class DeepLabModel(object):\n","  \"\"\"Class to load deeplab model and run inference.\"\"\"\n","\n","  INPUT_TENSOR_NAME = 'ImageTensor:0'\n","  OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n","  INPUT_SIZE = 513\n","  FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n","\n","  def __init__(self, tarball_path):\n","    \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n","    self.graph = tf.Graph()\n","\n","    graph_def = None\n","    # Extract frozen graph from tar archive.\n","    tar_file = tarfile.open(tarball_path)\n","    for tar_info in tar_file.getmembers():\n","      if self.FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n","        file_handle = tar_file.extractfile(tar_info)\n","        graph_def = tf.GraphDef.FromString(file_handle.read())\n","        break\n","\n","    tar_file.close()\n","\n","    if graph_def is None:\n","      raise RuntimeError('Cannot find inference graph in tar archive.')\n","\n","    with self.graph.as_default():\n","      tf.import_graph_def(graph_def, name='')\n","\n","    self.sess = tf.Session(graph=self.graph)\n","\n","  def run(self, image):\n","    \"\"\"Runs inference on a single image.\n","\n","    Args:\n","      image: A PIL.Image object, raw input image.\n","\n","    Returns:\n","      resized_image: RGB image resized from original input image.\n","      seg_map: Segmentation map of `resized_image`.\n","    \"\"\"\n","    # width, height = image.size\n","    # resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n","    # target_size = (int(resize_ratio * width), int(resize_ratio * height))\n","    # resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n","    # batch_seg_map = self.sess.run(\n","    #     self.OUTPUT_TENSOR_NAME,\n","    #     feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n","    # seg_map = batch_seg_map[0]\n","\n","    # For Video Process\n","    resized_image = image\n","    batch_seg_map = self.sess.run(\n","        self.OUTPUT_TENSOR_NAME,\n","        feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n","    seg_map = batch_seg_map[0]\n","\n","    return resized_image, seg_map\n","\n","\n","def create_pascal_label_colormap():\n","  \"\"\"Creates a label colormap used in PASCAL VOC segmentation benchmark.\n","\n","  Returns:\n","    A Colormap for visualizing segmentation results.\n","  \"\"\"\n","  colormap = np.zeros((256, 3), dtype=int)\n","  ind = np.arange(256, dtype=int)\n","\n","  for shift in reversed(range(8)):\n","    for channel in range(3):\n","      colormap[:, channel] |= ((ind >> channel) & 1) << shift\n","    ind >>= 3\n","\n","  return colormap\n","\n","\n","def label_to_color_image(label):\n","  \"\"\"Adds color defined by the dataset colormap to the label.\n","\n","  Args:\n","    label: A 2D array with integer type, storing the segmentation label.\n","\n","  Returns:\n","    result: A 2D array with floating type. The element of the array\n","      is the color indexed by the corresponding element in the input label\n","      to the PASCAL color map.\n","\n","  Raises:\n","    ValueError: If label is not of rank 2 or its value is larger than color\n","      map maximum entry.\n","  \"\"\"\n","  if label.ndim != 2:\n","    raise ValueError('Expect 2-D input label')\n","\n","  colormap = create_pascal_label_colormap()\n","\n","  if np.max(label) >= len(colormap):\n","    raise ValueError('label value too large.')\n","\n","  return colormap[label]\n","\n","\n","def vis_segmentation(image, seg_map):\n","  \"\"\"Visualizes input image, segmentation map and overlay view.\"\"\"\n","  plt.figure(figsize=(15, 5))\n","  grid_spec = gridspec.GridSpec(1, 4, width_ratios=[6, 6, 6, 1])\n","\n","  plt.subplot(grid_spec[0])\n","  plt.imshow(image)\n","  plt.axis('off')\n","  plt.title('input image')\n","\n","  plt.subplot(grid_spec[1])\n","  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n","  plt.imshow(seg_image)\n","  plt.axis('off')\n","  plt.title('segmentation map')\n","\n","  plt.subplot(grid_spec[2])\n","  plt.imshow(image)\n","  plt.imshow(seg_image, alpha=0.7)\n","  plt.axis('off')\n","  plt.title('segmentation overlay')\n","\n","  unique_labels = np.unique(seg_map)\n","  ax = plt.subplot(grid_spec[3])\n","  plt.imshow(\n","      FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest')\n","  ax.yaxis.tick_right()\n","  plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n","  plt.xticks([], [])\n","  ax.tick_params(width=0.0)\n","  plt.grid('off')\n","  plt.show()\n","\n","\n","LABEL_NAMES = np.asarray([\n","    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n","    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n","    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tv'\n","])\n","\n","FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n","FULL_COLOR_MAP = label_to_color_image(FULL_LABEL_MAP)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"39tBb6mL8hd9"},"source":["# Select a pretrained model\n","\n","MODEL_NAME = 'mobilenetv2_coco_voctrainaug'  # @param ['mobilenetv2_coco_voctrainaug', 'mobilenetv2_coco_voctrainval', 'xception_coco_voctrainaug', 'xception_coco_voctrainval']\n","\n","_DOWNLOAD_URL_PREFIX = 'http://download.tensorflow.org/models/'\n","_MODEL_URLS = {\n","    'mobilenetv2_coco_voctrainaug':\n","        'deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz',\n","    'mobilenetv2_coco_voctrainval':\n","        'deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz',\n","    'xception_coco_voctrainaug':\n","        'deeplabv3_pascal_train_aug_2018_01_04.tar.gz',\n","    'xception_coco_voctrainval':\n","        'deeplabv3_pascal_trainval_2018_01_04.tar.gz',\n","}\n","_TARBALL_NAME = 'deeplab_model.tar.gz'\n","\n","model_dir = tempfile.mkdtemp()\n","tf.gfile.MakeDirs(model_dir)\n","\n","download_path = os.path.join(model_dir, _TARBALL_NAME)\n","print('downloading model, this might take a while...')\n","urllib.request.urlretrieve(_DOWNLOAD_URL_PREFIX + _MODEL_URLS[MODEL_NAME],\n","                   download_path)\n","print('download completed! loading DeepLab model...')\n","\n","MODEL = DeepLabModel(download_path)\n","print('model loaded successfully!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vwHe7uZu83p1"},"source":["# For output video by OpenCV \n","\n","capW = 0\n","capH = 0\n","frame_count = 0\n","fps = 0\n","\n","# Set path to the video file.\n","input_video  = \"/content/drive/MyDrive/hoge/input.mp4\"\n","output_video = \"/content/drive/MyDrive/hoge/output.mp4\"\n","\n","capture = cv2.VideoCapture(input_video)\n","\n","#fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n","fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n","fps = capture.get(cv2.CAP_PROP_FPS)\n","frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n","capW = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n","capH = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","writer = cv2.VideoWriter(output_video, fourcc, fps, (capW, capH))\n","\n","print(\"fps:\",fps)\n","print(\"frame_count:\",frame_count)\n","print(\"(W, H) =\",capW, capH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pt6DAIIJAWNW"},"source":["# cv2.imshow cannot be used with colab\n","from google.colab.patches import cv2_imshow\n","\n","def run_visualization():\n","  for i in range(frame_count):\n","    ret, frame = capture.read()\n","    if ret==True:\n","      original_img = cv2.resize(frame,(500,375))\n","      resized_img, seg_map = MODEL.run(original_img)\n","      \n","      #vis_segmentation(resized_img, seg_map)\n","\n","      seg_img = label_to_color_image(seg_map).astype(np.uint8)\n","      result_img = cv2.add(resized_img, seg_img)\n","      #seg_img = cv2.resize(seg_img,(capW,capH))\n","      result_img = cv2.resize(result_img,(capW,capH))\n","\n","      #writer.write(frame)\n","      #writer.write(seg_img)\n","      writer.write(result_img)\n","    else:\n","      print(\"Can't read frame...\")\n","      break\n","  # Release\n","  writer.release()\n","  capture.release()\n","  cv2.destroyAllWindows()\n","  print(\"Finished...\")\n","\n","# Run model\n","run_visualization()\n"],"execution_count":null,"outputs":[]}]}